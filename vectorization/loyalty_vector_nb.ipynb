{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Vectorization Pipeline Components:\n",
    "1. Chroma Integration\n",
    "2. Semantic Document Preparation\n",
    "3. Semantic Search Testing\n",
    "4. Database Analytics\n",
    "\n",
    "##### Usage Flow:\n",
    "- Input: classification/results/output.csv from classification/loyalty_classifier_nb notebook\n",
    "- Processing: Convert semantic classifications to embeddings\n",
    "- Output: Searchable vector database for RAG queries\n",
    "\n",
    "##### Test Queries Included:\n",
    "- \"loyalty points calculation rules\"\n",
    "- \"order processing workflow\"\n",
    "- \"customer data integration\"\n",
    "- \"payment service integration\"\n",
    "- \"business rule patterns\""
   ],
   "id": "505aa5476144b2ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:28:59.606461Z",
     "start_time": "2025-07-10T12:28:59.601457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CLASSIFICATION_CSV = \"../classification/results/{llm}/output.csv\"\n",
    "DB_PATH = \"results/{embedder}/chroma_db\"\n",
    "COLLECTION_NAME = \"loyalty_code_semantics_{llm}\"\n",
    "# \"all-MiniLM-L6-v2\",      # Fast, good general purpose\n",
    "# \"all-mpnet-base-v2\",     # Better quality, slower\n",
    "# \"multi-qa-MiniLM-L6-cos-v1\"  # Optimized for Q&A\n",
    "\n",
    "def setup(llm: str, embedder: str):\n",
    "    config = { \"llm\": llm, \"embedder\": embedder }\n",
    "\n",
    "    classification_csv = CLASSIFICATION_CSV.format(**config)\n",
    "    db_path = DB_PATH.format(**config)\n",
    "    collection_name = COLLECTION_NAME.format(**config)\n",
    "\n",
    "    return classification_csv, db_path, collection_name"
   ],
   "id": "718b9f535ca19243",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-10T12:29:03.256580Z",
     "start_time": "2025-07-10T12:29:02.009966Z"
    }
   },
   "source": [
    "from vectorization.document_utils import prepare_documents_for_embedding, load_classification_data\n",
    "import json\n",
    "\n",
    "from vectorization.semantic_vector_database import SemanticVectorDatabase\n",
    "\n",
    "def run_vectorization_pipeline(db_path: str,\n",
    "                                    classification_csv: str,\n",
    "                                    collection_name: str,\n",
    "                                    embedding_model: str,\n",
    "                                    reset_db: bool = True):\n",
    "    \"\"\"Main pipeline to create vector database from classification results\"\"\"\n",
    "\n",
    "    print(\"=== CodeSense Vector Database Creation ===\")\n",
    "\n",
    "    # Initialize database\n",
    "    vector_db = SemanticVectorDatabase(db_path, embedding_model)\n",
    "\n",
    "    # Create collection\n",
    "    collection = vector_db.create_collection(collection_name, reset_db)\n",
    "\n",
    "    # Prepare documents from classification data\n",
    "    df = load_classification_data(classification_csv)\n",
    "    documents = prepare_documents_for_embedding(df)\n",
    "\n",
    "    # Add to collection\n",
    "    collection.add_documents_to_collection(documents)\n",
    "\n",
    "    # Get collection statistics\n",
    "    stats = collection.get_collection_stats_v1()\n",
    "    print(f\"\\n=== Collection Statistics ===\")\n",
    "    print(json.dumps(stats, indent=2, default=str))\n",
    "\n",
    "    # Test semantic search\n",
    "    test_queries = [\n",
    "        \"loyalty points calculation rules\",\n",
    "        \"order processing workflow\",\n",
    "        \"customer data integration\",\n",
    "        \"payment service integration\",\n",
    "        \"business rule patterns\"\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n=== Testing Semantic Search ===\")\n",
    "    for query in test_queries:\n",
    "        collection.semantic_search(query, n_results=3)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Running Vectorization with Anthropic set and  all-MiniLM-L6-v2 ===\")\n",
    "classification_csv, db_path, collection_name = setup(\"claude3.5\", \"all-MiniLM-L6-v2\")\n",
    "run_vectorization_pipeline(db_path=db_path, classification_csv=classification_csv, collection_name=collection_name, embedding_model=\"all-MiniLM-L6-v2\")"
   ],
   "id": "ca0391e516dd7bd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Running Vectorization with Anthropic set and  all-mpnet-base-v2 ===\")\n",
    "classification_csv, db_path, collection_name = setup(\"claude3.5\", \"all-mpnet-base-v2\")\n",
    "run_vectorization_pipeline(db_path=db_path, classification_csv=classification_csv, collection_name=collection_name, embedding_model=\"all-mpnet-base-v2\")"
   ],
   "id": "779d57e91a8d07d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Running Vectorization with Ollama set and  all-MiniLM-L6-v2 ===\")\n",
    "classification_csv, db_path, collection_name = setup(\"codellama\", \"all-MiniLM-L6-v2\")\n",
    "run_vectorization_pipeline(db_path=db_path, classification_csv=classification_csv, collection_name=collection_name, embedding_model=\"all-MiniLM-L6-v2\")"
   ],
   "id": "a3a45767151cdefd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Running Vectorization with Ollama set and  all-mpnet-base-v2 ===\")\n",
    "classification_csv, db_path, collection_name = setup(\"codellama\", \"all-mpnet-base-v2\")\n",
    "run_vectorization_pipeline(db_path=db_path, classification_csv=classification_csv, collection_name=collection_name, embedding_model=\"all-mpnet-base-v2\")"
   ],
   "id": "4dc6c4252546a64c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Running Vectorization with OpenAI set and  all-MiniLM-L6-v2 ===\")\n",
    "classification_csv, db_path, collection_name = setup(\"gpt4.1\", \"all-MiniLM-L6-v2\")\n",
    "run_vectorization_pipeline(db_path=db_path, classification_csv=classification_csv, collection_name=collection_name, embedding_model=\"all-MiniLM-L6-v2\")"
   ],
   "id": "bad0df03a9248127",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Running Vectorization with OpenAI set and  all-mpnet-base-v2 ===\")\n",
    "classification_csv, db_path, collection_name = setup(\"gpt4.1\", \"all-mpnet-base-v2\")\n",
    "run_vectorization_pipeline(db_path=db_path, classification_csv=classification_csv, collection_name=collection_name, embedding_model=\"all-mpnet-base-v2\")"
   ],
   "id": "1300e9021e35079f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
