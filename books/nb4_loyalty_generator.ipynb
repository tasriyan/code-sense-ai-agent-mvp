{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T19:58:00.333812Z",
     "start_time": "2025-07-12T19:57:59.461362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from vectorization.semantic_vector_database import SemanticVectorDatabase\n",
    "from llms.providers import LLMRecommender\n",
    "from generation.generator_simple import CodeSenseGenerator\n",
    "from rag.rag import BasicContentRag\n",
    "\n",
    "# Test requests\n",
    "test_requests = [\n",
    "    \"I want to add a new rule to calculate loyalty points\",\n",
    "    \"Create a new loyalty point reward for VIP customers\",\n",
    "    \"Add validation for minimum order amount in loyalty rules\",\n",
    "    \"Implement a service to check customer loyalty status\",\n",
    "    \"Add integration with payment service for loyalty points\"\n",
    "]\n",
    "\n",
    "generation_results = \"results/generation\"\n",
    "def run_generator(vector: SemanticVectorDatabase, embedding_model: str, collection_name: str, recommender: LLMRecommender):\n",
    "    \"\"\"Demo function to test implementation generation\"\"\"\n",
    "\n",
    "    collection = vector.get_collection(collection_name)\n",
    "    rag = BasicContentRag(collection)\n",
    "\n",
    "    generator = CodeSenseGenerator(recommender, rag)\n",
    "\n",
    "    for sequence, request in enumerate(test_requests):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TESTING REQUEST: {request}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        try:\n",
    "            # Generate suggestion\n",
    "            coding_advice = generator.fetch_coding_advice(\n",
    "                user_request=request\n",
    "            )\n",
    "\n",
    "            # Display results\n",
    "            coding_advice.display()\n",
    "\n",
    "            # Save suggestion\n",
    "            coding_advice.save(f\"{generation_results}/{embedding_model}/{collection_name}/test{sequence}.json\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error testing {recommender}: {e}\")"
   ],
   "id": "1e8e0cf649f77e57",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llms.anthropic import AnthropicRecommender\n",
    "from llms.ollama import OllamaRecommender\n",
    "from llms.openai import OpenAIRecommender\n",
    "from vectorization.semantic_vector_database import SemanticVectorDatabase\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "vector_results = \"results/vectorization\"\n",
    "rag_results = \"results/rag\"\n",
    "\n",
    "chroma_base = \"{model}/loyalty_points_kb\"\n",
    "\n",
    "loyalty_collection = \"loyalty_code_semantics_{llm}\"\n",
    "anthropic = AnthropicRecommender(os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "ollama = OllamaRecommender()\n",
    "openai = OpenAIRecommender(os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"model\": \"all-MiniLM-L6-v2\",\n",
    "        \"llms\": [ \"claude3.5\", \"claude3.7\", \"claude4.0\", \"codellama\", \"gpt4.1\"],\n",
    "        \"recommenders\": [anthropic, ollama, openai]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"all-mpnet-base-v2\",\n",
    "        \"llms\": [ \"claude3.5\", \"claude3.7\", \"claude4.0\", \"codellama\", \"gpt4.1\"],\n",
    "        \"recommenders\": [anthropic, ollama, openai]\n",
    "    }\n",
    "]\n",
    "\n",
    "rag_testers = []\n",
    "reports = []\n",
    "\n",
    "for model in models:\n",
    "    embedding_model = model[\"model\"]\n",
    "    print(\"embedding_model: \", embedding_model)\n",
    "    db_path = f\"{vector_results}/{chroma_base.format(model=embedding_model)}\"\n",
    "    print(\"db_path: \", db_path)\n",
    "\n",
    "    for i, llm in enumerate(model[\"llms\"]):\n",
    "        collection_name = loyalty_collection.format(llm=llm)\n",
    "        recommenders = model[\"recommenders\"][i]\n",
    "\n",
    "        vector_db = SemanticVectorDatabase(db_path, embedding_model)\n",
    "        run_generator(vector_db, embedding_model, collection_name, recommenders)\n"
   ],
   "id": "3e873f7e9c6e8113",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
