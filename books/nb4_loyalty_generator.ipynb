{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from generation.implementation_suggestion import NoSuggestion\n",
    "\n",
    "generation_results = \"results/generation\"\n",
    "collection_name = \"books_test\"\n",
    "sequence = 0\n",
    "\n",
    "suggestion = NoSuggestion()\n",
    "suggestion.save_suggestion(f\"{generation_results}/{collection_name}/test{sequence}.json\")"
   ],
   "id": "ae6522e3416c3ba2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-12T04:23:08.899385Z",
     "start_time": "2025-07-12T04:23:08.039109Z"
    }
   },
   "source": [
    "from vectorization.semantic_vector_database import SemanticVectorDatabase\n",
    "from llm_providers.llm_provider import LLMExecutor\n",
    "from generation.semantic_data_retriever import SemanticDataRetriever\n",
    "from generation.code_sense import CodeSenseImplementationGenerator\n",
    "\n",
    "# Test requests\n",
    "test_requests = [\n",
    "    \"I want to add a new rule to calculate loyalty points\",\n",
    "    \"Create a new loyalty point reward for VIP customers\",\n",
    "    \"Add validation for minimum order amount in loyalty rules\",\n",
    "    \"Implement a service to check customer loyalty status\",\n",
    "    \"Add integration with payment service for loyalty points\"\n",
    "]\n",
    "\n",
    "generation_results = \"results/generation\"\n",
    "def run_generator(vector: SemanticVectorDatabase, collection_name: str, provider_to_test: LLMExecutor):\n",
    "    \"\"\"Demo function to test implementation generation\"\"\"\n",
    "\n",
    "    collection = vector.get_collection(collection_name)\n",
    "    retriever = SemanticDataRetriever(collection)\n",
    "\n",
    "    generator = CodeSenseImplementationGenerator(retriever, provider_to_test)\n",
    "\n",
    "    for sequence, request in enumerate(test_requests):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TESTING REQUEST: {request}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        try:\n",
    "            # Generate suggestion\n",
    "            suggestion = generator.generate_complete_suggestion(\n",
    "                user_request=request\n",
    "            )\n",
    "\n",
    "            # Display results\n",
    "            suggestion.display_suggestion()\n",
    "\n",
    "            # Save suggestion\n",
    "            suggestion.save_suggestion(f\"{generation_results}/{collection_name}/test{sequence}.json\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error testing {provider_to_test}: {e}\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llm_providers.anthropic import AnthropicExecutor\n",
    "from llm_providers.ollama import OllamaExecutor\n",
    "from llm_providers.openai import OpenAIExecutor\n",
    "from vectorization.semantic_vector_database import SemanticVectorDatabase\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "vector_results = \"results/vectorization\"\n",
    "rag_results = \"results/rag\"\n",
    "\n",
    "chroma_base = \"{model}/loyalty_points_kb\"\n",
    "\n",
    "loyalty_collection = \"loyalty_code_semantics_{llm}\"\n",
    "anthropic = AnthropicExecutor(os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "ollama = OllamaExecutor()\n",
    "openai = OpenAIExecutor(os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"model\": \"all-MiniLM-L6-v2\",\n",
    "        \"llms\": [\"claude3.5\", \"codellama\", \"gpt4.1\"],\n",
    "        \"providers\": [anthropic, ollama, openai]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"all-mpnet-base-v2\",\n",
    "        \"llms\": [\"claude3.5\", \"codellama\", \"gpt4.1\"],\n",
    "        \"providers\": [anthropic, ollama, openai]\n",
    "    }\n",
    "]\n",
    "\n",
    "rag_testers = []\n",
    "reports = []\n",
    "\n",
    "for model in models:\n",
    "    embedding_model = model[\"model\"]\n",
    "    print(\"embedding_model: \", embedding_model)\n",
    "    db_path = f\"{vector_results}/{chroma_base.format(model=embedding_model)}\"\n",
    "    print(\"db_path: \", db_path)\n",
    "\n",
    "    # Fix: Use enumerate() to get both index and value\n",
    "    for i, llm in enumerate(model[\"llms\"]):\n",
    "        # Fix: Use the llm string directly since it's already a string\n",
    "        collection_name = loyalty_collection.format(llm=llm)\n",
    "        provider = model[\"providers\"][i]\n",
    "\n",
    "        vector_db = SemanticVectorDatabase(db_path, embedding_model)\n",
    "        run_generator(vector_db, collection_name, provider)\n"
   ],
   "id": "3e873f7e9c6e8113",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
